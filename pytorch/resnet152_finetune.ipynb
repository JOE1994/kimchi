{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bson\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import struct\n",
    "from PIL import Image\n",
    "from  torchvision import transforms as transf\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_bson(bson_path, with_categories, input_count):\n",
    "    \"\"\"\n",
    "    Reads BSON\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    rows = {}\n",
    "    with open(bson_path, \"rb\") as f, tqdm(total=input_count) as pbar:\n",
    "        f.seek(offset)\n",
    "        records_read = 0\n",
    "        while True:\n",
    "            item_length_bytes = f.read(4)\n",
    "            if len(item_length_bytes) == 0:\n",
    "                break\n",
    "\n",
    "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n",
    "            f.seek(offset)\n",
    "            item_data = f.read(length)\n",
    "            assert len(item_data) == length\n",
    "\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            product_id = item[\"_id\"]\n",
    "            num_imgs = len(item[\"imgs\"])\n",
    "\n",
    "            row = [num_imgs, offset, length]\n",
    "            if with_categories:\n",
    "                row += [item[\"category_id\"]]\n",
    "            rows[product_id] = row\n",
    "\n",
    "            offset += length\n",
    "            f.seek(offset)\n",
    "            records_read += 1\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    columns = [\"num_imgs\", \"offset\", \"length\"]\n",
    "    if with_categories:\n",
    "        columns += [\"category_id\"]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
    "    df.index.name = \"product_id\"\n",
    "    df.columns = columns\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def make_category_tables(categories_path):\n",
    "    \"\"\"\n",
    "    Converts category name into an index [0, N-1]\n",
    "    \"\"\"\n",
    "    categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n",
    "    categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n",
    "\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    for ir in categories_df.itertuples():\n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "    return cat2idx, idx2cat\n",
    "\n",
    "\n",
    "def get_obs(fname, offset, length):\n",
    "    fobj = open(fname, 'rb')\n",
    "    fobj.seek(offset)\n",
    "    res = bson.BSON.decode(fobj.read(length))\n",
    "    fobj.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(data_utils.Dataset):\n",
    "    def __init__(self, dataset, split, transform):\n",
    "        self.dataset = dataset\n",
    "        self.metadata = split\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        entry = self.metadata.iloc[index]\n",
    "        num_imgs, offset, length, target = entry\n",
    "        obs = get_obs(self.dataset, offset, length)\n",
    "        keep = np.random.choice(len(obs['imgs']))\n",
    "        byte_str = obs['imgs'][keep]['picture']\n",
    "        img = cv2.imdecode(np.fromstring(byte_str, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.index.values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD PRETRAINED MODEL.\n",
    "resnet152 = models.resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = 5270 # TOTAL NUMBER OF CATEGORIES of this classification task.\n",
    "\n",
    "# WHEN FINE-TUNING, set param.requires_grad = False.\n",
    "for param in resnet152.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = resnet152.fc.in_features\n",
    "resnet152.fc = torch.nn.Linear(num_ftrs, NUM_CATEGORIES)\n",
    "\n",
    "resnet152 = torch.nn.DataParallel(resnet152, device_ids=[0,1,2,3]).cuda() # SET MODEL TO GPU MODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(num_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss, Optimizer, LR Scheduler.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opoosed to before.\n",
    "optimizer = torch.optim.SGD(resnet152.module.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7069896/7069896 [01:38<00:00, 72064.44it/s]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BSON_FILE = '/home/joe/term/input/train.bson'\n",
    "TEST_BSON_FILE = '/home/joe/term/input/test.bson'\n",
    "CATEGS = '/home/joe/term/input/category_names.csv'\n",
    "N_TRAIN = 7069896 # number of items in train.bson\n",
    "\n",
    "# mapping the catigores into 0-5269 range\n",
    "cat2idx, idx2cat = make_category_tables(CATEGS)\n",
    "\n",
    "# Dataset and loader\n",
    "\n",
    "# Scanning the metadata\n",
    "meta_data = read_bson(TRAIN_BSON_FILE, with_categories=True, input_count = N_TRAIN)\n",
    "meta_data.category_id = np.array([cat2idx[ind] for ind in meta_data.category_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (1100000, 4) (69896, 4)\n",
      "0.9992264053635895\n"
     ]
    }
   ],
   "source": [
    "temp = np.arange(N_TRAIN)\n",
    "np.random.shuffle(temp)\n",
    "\n",
    "train_sample = temp[0:1100000] # CONTROL SAMPLE SIZE FROM TRAINING-SET. \n",
    "val_sample = temp[7000000:N_TRAIN]\n",
    "\n",
    "train_data = meta_data.iloc[train_sample]\n",
    "val_data = meta_data.iloc[val_sample]\n",
    "\n",
    "print(type(train_data), train_data.shape, val_data.shape)\n",
    "\n",
    "training_category = np.unique(np.array(train_data.category_id))\n",
    "val_category = np.unique(np.array(val_data.category_id))\n",
    "\n",
    "both = np.intersect1d(training_category, val_category)\n",
    "\n",
    "both_ratio = 1.0 * len(both)/len(val_category)\n",
    "\n",
    "print(both_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "BS = 128\n",
    "\n",
    "train_dataset = CdiscountDataset(TRAIN_BSON_FILE, train_data, transf.Compose([\n",
    "    transf.RandomCrop(160),\n",
    "    transf.Resize(224),\n",
    "    transf.ColorJitter(0.15, 0.15, 0.15, 0.15),\n",
    "    transf.RandomHorizontalFlip(),\n",
    "    transf.ToTensor(),\n",
    "    transf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "loader = data_utils.DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=N_THREADS, pin_memory = True)\n",
    "\n",
    "val_dataset = CdiscountDataset(TRAIN_BSON_FILE, val_data, transf.Compose([\n",
    "    transf.Resize(224),\n",
    "    transf.ToTensor(),\n",
    "    transf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "val_loader = data_utils.DataLoader(val_dataset, batch_size=BS, shuffle=False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8594/8594 [9:10:36<00:00,  3.58s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th accuracy of the network on the 547 test images: 0.004292 %\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resnet34' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dd5673c9b3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mresnet152\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Simply set module back to training mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%dth accuracy of the network on the %d test images: %f %%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet34\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./models/resnet152_fc_{}epoch.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet34' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCH = 3\n",
    "cnt = 0\n",
    "# Let's go fetch some data!\n",
    "torch.backends.cudnn.benchmark = True\n",
    "for epoch in range(EPOCH):\n",
    "    pbar = tqdm(total=len(loader))\n",
    "    for i, (batch, target) in enumerate(loader):\n",
    "        exp_lr_scheduler.step()\n",
    "        # Convert torch tensor to Variable\n",
    "        images = Variable(batch.cuda())\n",
    "        labels = Variable(target.cuda())\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = resnet152(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "    # Test the Model\n",
    "    resnet152.eval() # simply set module to evaluation mode.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch, target in val_loader:\n",
    "        images = Variable(batch, volatile=True).cuda()\n",
    "        outputs = resnet152(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted.cpu() == target).sum()\n",
    "    resnet152.train() # Simply set module back to training mode.\n",
    "    print('%dth accuracy of the network on the %d test images: %f %%' % (epoch+1, len(val_loader), (100.0 * correct / total)))\n",
    "    torch.save(resnet34.state_dict(), './models/resnet152_fc_{}epoch.pkl'.format(epoch+1))\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
