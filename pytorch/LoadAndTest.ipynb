{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bson\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import struct\n",
    "from PIL import Image\n",
    "from  torchvision import transforms as transf\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_bson(bson_path, with_categories, num_input):\n",
    "    \"\"\"\n",
    "    Reads BSON\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    rows = {}\n",
    "    with open(bson_path, \"rb\") as f, tqdm(total=num_input) as pbar:\n",
    "        f.seek(offset)\n",
    "        records_read = 0\n",
    "        while True:\n",
    "            item_length_bytes = f.read(4)\n",
    "            if len(item_length_bytes) == 0:\n",
    "                break\n",
    "\n",
    "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n",
    "            f.seek(offset)\n",
    "            item_data = f.read(length)\n",
    "            assert len(item_data) == length\n",
    "\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            product_id = item[\"_id\"]\n",
    "            num_imgs = len(item[\"imgs\"])\n",
    "\n",
    "            row = [num_imgs, offset, length]\n",
    "            if with_categories:\n",
    "                row += [item[\"category_id\"]]\n",
    "            rows[product_id] = row\n",
    "\n",
    "            offset += length\n",
    "            f.seek(offset)\n",
    "            records_read += 1\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    columns = [\"num_imgs\", \"offset\", \"length\"]\n",
    "    if with_categories:\n",
    "        columns += [\"category_id\"]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
    "    df.index.name = \"product_id\"\n",
    "    df.columns = columns\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_category_tables(categories_path):\n",
    "    \"\"\"\n",
    "    Converts category name into an index [0, N-1]\n",
    "    \"\"\"\n",
    "    categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n",
    "    categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n",
    "\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    for ir in categories_df.itertuples():\n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "    return cat2idx, idx2cat\n",
    "\n",
    "\n",
    "def get_obs(fname, offset, length):\n",
    "    fobj = open(fname, 'rb')\n",
    "    fobj.seek(offset)\n",
    "    res = bson.BSON.decode(fobj.read(length))\n",
    "    fobj.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(data_utils.Dataset):\n",
    "    def __init__(self, dataset, split, transform):\n",
    "        self.dataset = dataset\n",
    "        self.metadata = split\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        entry = self.metadata.iloc[index]\n",
    "        num_imgs, offset, length = entry\n",
    "        obs = get_obs(self.dataset, offset, length)\n",
    "        keep = np.random.choice(len(obs['imgs']))\n",
    "        byte_str = obs['imgs'][keep]['picture']\n",
    "        img = cv2.imdecode(np.fromstring(byte_str, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.index.values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1768182/1768182 [01:02<00:00, 28076.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# read in test data.\n",
    "TEST_NUM = 1768182\n",
    "TEST_BSON_FILE = '/home/joe/term/input/test.bson'\n",
    "\n",
    "meta_data = read_bson(TEST_BSON_FILE, with_categories=False, num_input=TEST_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGS = '/home/joe/term/input/category_names.csv'\n",
    "\n",
    "# mapping the catigores into 0-5269 range\n",
    "cat2idx, idx2cat = make_category_tables(CATEGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BS = 3072 # Batch size\n",
    "\n",
    "test_dataset = CdiscountDataset(TEST_BSON_FILE, meta_data, transf.Compose([\n",
    "        transf.Resize(224),\n",
    "        transf.ToTensor(),\n",
    "        transf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]))\n",
    "test_loader = data_utils.DataLoader(test_dataset, batch_size=BS, shuffle=False, pin_memory=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Resnet18 Class.\n",
    "resnet18 = models.resnet18()\n",
    "\n",
    "NUM_CATEGORIES = 5270 # TOTAL NUMBER OF CATEGORIES of this classification task.\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = torch.nn.Linear(num_ftrs, NUM_CATEGORIES)\n",
    "\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "resnet18 = torch.nn.DataParallel(resnet18, device_ids=[0,1,2,3]).cuda() # SET MODEL TO GPU MODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trained parameters.\n",
    "resnet18.load_state_dict(torch.load('/home/joe/term/term/pytorch/models/resnet18_fc6_6epoch.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d (3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d (64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d (128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    (fc): Linear(in_features=512, out_features=5270)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.eval() # set model to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1768182/1768182 [46:34<00:00, 641.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's run the model on the Test-set.\n",
    "\n",
    "evaluations = np.array([])\n",
    "\n",
    "with tqdm(total = TEST_NUM) as pbar:\n",
    "    for batch in test_loader:\n",
    "        images = Variable(batch, volatile=True).cuda()\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        evaluations = np.concatenate((evaluations, predicted.cpu().numpy()), axis=0)\n",
    "        pbar.update(batch.size(0))\n",
    "        pass\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_data['category_id'] = pd.Series(evaluations.astype(int), index=meta_data.index)\n",
    "final_result = meta_data.drop(['num_imgs', 'offset', 'length'], axis=1)\n",
    "final_result.index.names = ['_id']\n",
    "final_result['category_id'] = final_result['category_id'].map(idx2cat)\n",
    "final_result.to_csv('/home/joe/term/output/resnet18_fc_6epoch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
