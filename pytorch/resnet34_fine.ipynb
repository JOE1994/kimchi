{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bson\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import struct\n",
    "from PIL import Image\n",
    "from  torchvision import transforms as transf\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_bson(bson_path, with_categories, input_count):\n",
    "    \"\"\"\n",
    "    Reads BSON\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    rows = {}\n",
    "    with open(bson_path, \"rb\") as f, tqdm(total=input_count) as pbar:\n",
    "        f.seek(offset)\n",
    "        records_read = 0\n",
    "        while True:\n",
    "            item_length_bytes = f.read(4)\n",
    "            if len(item_length_bytes) == 0:\n",
    "                break\n",
    "\n",
    "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n",
    "            f.seek(offset)\n",
    "            item_data = f.read(length)\n",
    "            assert len(item_data) == length\n",
    "\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            product_id = item[\"_id\"]\n",
    "            num_imgs = len(item[\"imgs\"])\n",
    "\n",
    "            row = [num_imgs, offset, length]\n",
    "            if with_categories:\n",
    "                row += [item[\"category_id\"]]\n",
    "            rows[product_id] = row\n",
    "\n",
    "            offset += length\n",
    "            f.seek(offset)\n",
    "            records_read += 1\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    columns = [\"num_imgs\", \"offset\", \"length\"]\n",
    "    if with_categories:\n",
    "        columns += [\"category_id\"]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
    "    df.index.name = \"product_id\"\n",
    "    df.columns = columns\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def make_category_tables(categories_path):\n",
    "    \"\"\"\n",
    "    Converts category name into an index [0, N-1]\n",
    "    \"\"\"\n",
    "    categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n",
    "    categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n",
    "\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    for ir in categories_df.itertuples():\n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "    return cat2idx, idx2cat\n",
    "\n",
    "\n",
    "def get_obs(fname, offset, length):\n",
    "    fobj = open(fname, 'rb')\n",
    "    fobj.seek(offset)\n",
    "    res = bson.BSON.decode(fobj.read(length))\n",
    "    fobj.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(data_utils.Dataset):\n",
    "    def __init__(self, dataset, split, transform):\n",
    "        self.dataset = dataset\n",
    "        self.metadata = split\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        entry = self.metadata.iloc[index]\n",
    "        num_imgs, offset, length, target = entry\n",
    "        obs = get_obs(self.dataset, offset, length)\n",
    "        keep = np.random.choice(len(obs['imgs']))\n",
    "        byte_str = obs['imgs'][keep]['picture']\n",
    "        img = cv2.imdecode(np.fromstring(byte_str, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.index.values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD PRETRAINED MODEL.\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "\n",
    "NUM_CATEGORIES = 5270 # TOTAL NUMBER OF CATEGORIES of this classification task.\n",
    "\n",
    "# WHEN FINE-TUNING, set param.requires_grad = False.\n",
    "for param in resnet34.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = resnet34.fc.in_features\n",
    "resnet34.fc = torch.nn.Linear(num_ftrs, NUM_CATEGORIES)\n",
    "\n",
    "resnet34 = torch.nn.DataParallel(resnet34, device_ids=[0,1,2,3]).cuda() # SET MODEL TO GPU MODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7069896/7069896 [04:11<00:00, 28089.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# Here, optimize only the last fc layer of Resnet18.\n",
    "optimizer = torch.optim.Adam(resnet34.module.fc.parameters(), weight_decay=1e-5) # Adam default Learning Rate : 0.001\n",
    "\n",
    "TRAIN_BSON_FILE = '/home/joe/term/input/train.bson'\n",
    "TEST_BSON_FILE = '/home/joe/term/input/test.bson'\n",
    "CATEGS = '/home/joe/term/input/category_names.csv'\n",
    "N_TRAIN = 7069896 # number of items in train.bson\n",
    "\n",
    "# mapping the catigores into 0-5269 range\n",
    "cat2idx, idx2cat = make_category_tables(CATEGS)\n",
    "\n",
    "# Dataset and loader\n",
    "\n",
    "# Scanning the metadata\n",
    "meta_data = read_bson(TRAIN_BSON_FILE, with_categories=True, input_count = N_TRAIN)\n",
    "meta_data.category_id = np.array([cat2idx[ind] for ind in meta_data.category_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (1400000, 4) (69896, 4)\n",
      "0.99948625738505\n"
     ]
    }
   ],
   "source": [
    "temp = np.arange(N_TRAIN)\n",
    "np.random.shuffle(temp)\n",
    "\n",
    "train_sample = temp[0:7000000] # CONTROL SAMPLE SIZE FROM TRAINING-SET. \n",
    "val_sample = temp[7000000:N_TRAIN]\n",
    "\n",
    "train_data = meta_data.iloc[train_sample]\n",
    "val_data = meta_data.iloc[val_sample]\n",
    "\n",
    "print(type(train_data), train_data.shape, val_data.shape)\n",
    "\n",
    "training_category = np.unique(np.array(train_data.category_id))\n",
    "val_category = np.unique(np.array(val_data.category_id))\n",
    "\n",
    "both = np.intersect1d(training_category, val_category)\n",
    "\n",
    "both_ratio = 1.0 * len(both)/len(val_category)\n",
    "\n",
    "print(both_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "BS = 600\n",
    "\n",
    "train_dataset = CdiscountDataset(TRAIN_BSON_FILE, train_data, transf.Compose([\n",
    "    transf.Resize(224),\n",
    "    transf.RandomHorizontalFlip(),\n",
    "    transf.ToTensor(),\n",
    "    transf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "loader = data_utils.DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=N_THREADS, pin_memory = True)\n",
    "\n",
    "val_dataset = CdiscountDataset(TRAIN_BSON_FILE, val_data, transf.Compose([\n",
    "    transf.Resize(224),\n",
    "    transf.ToTensor(),\n",
    "    transf.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "val_loader = data_utils.DataLoader(val_dataset, batch_size=BS, shuffle=False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:13:32<00:00,  3.99s/it]  \n",
      "  0%|          | 0/2334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th accuracy of the network on the 117 test images: 41.756324 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:14:07<00:00,  4.01s/it]  \n",
      "  0%|          | 0/2334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th accuracy of the network on the 117 test images: 43.547556 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:14:11<00:00,  4.01s/it]  \n",
      "  0%|          | 0/2334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th accuracy of the network on the 117 test images: 44.610564 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:13:37<00:00,  3.98s/it]  \n",
      "  0%|          | 0/2334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th accuracy of the network on the 117 test images: 44.813723 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:13:20<00:00,  3.99s/it]  \n",
      "  0%|          | 0/2334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th accuracy of the network on the 117 test images: 45.426062 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:14:02<00:00,  4.01s/it]  \n",
      "  0%|          | 0/2334 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th accuracy of the network on the 117 test images: 45.491874 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2334/2334 [3:13:57<00:00,  3.99s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th accuracy of the network on the 117 test images: 45.677864 %\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 7\n",
    "\n",
    "# Let's go fetch some data!\n",
    "torch.backends.cudnn.benchmark = True\n",
    "for epoch in range(EPOCH):\n",
    "    pbar = tqdm(total=len(loader))\n",
    "    for i, (batch, target) in enumerate(loader):\n",
    "        # Convert torch tensor to Variable\n",
    "        images = Variable(batch.cuda())\n",
    "        labels = Variable(target.cuda())\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = resnet34(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "    # Test the Model\n",
    "    resnet34.eval() # simply set module to evaluation mode.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch, target in val_loader:\n",
    "        images = Variable(batch, volatile=True).cuda()\n",
    "        outputs = resnet34(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted.cpu() == target).sum()\n",
    "    resnet34.train() # Simply set module back to training mode.\n",
    "    print('%dth accuracy of the network on the %d test images: %f %%' % (epoch, len(val_loader), (100.0 * correct / total)))\n",
    "    torch.save(resnet34.state_dict(), './models/resnet34_fc6_{}epoch.pkl'.format(epoch+1))\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
